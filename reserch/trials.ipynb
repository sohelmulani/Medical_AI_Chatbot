{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d2d5da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"c:\\\\Users\\\\muska\\\\Desktop\\\\Sohel's Space\\\\Projects\\\\AI_Medical_Assistant\\\\Medical_AiBot\\\\reserch\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "610a16ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3687d244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"c:\\\\Users\\\\muska\\\\Desktop\\\\Sohel's Space\\\\Projects\\\\AI_Medical_Assistant\\\\Medical_AiBot\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ede892",
   "metadata": {},
   "source": [
    "1. Data Extaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b31dd64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing mdoules to load pdf files\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23fa613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf(data):\n",
    "    loader= DirectoryLoader(\n",
    "        data,\n",
    "        glob=\"*.pdf\",\n",
    "        loader_cls=PyPDFLoader,\n",
    "    )\n",
    "\n",
    "    document= loader.load()\n",
    "\n",
    "    print(f\"Number of documents loaded: {len(document)}\")\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b56339c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents loaded: 637\n"
     ]
    }
   ],
   "source": [
    "docs= get_pdf(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df96ce41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'PDFlib+PDI 5.0.0 (SunOS)',\n",
       " 'creator': 'PyPDF',\n",
       " 'creationdate': '2004-12-18T17:00:02-05:00',\n",
       " 'moddate': '2004-12-18T16:15:31-06:00',\n",
       " 'source': 'data\\\\Medical_book.pdf',\n",
       " 'total_pages': 637,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c95d141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "\"\"\"function to clean metadata of documents\"\"\"\n",
    "\n",
    "def clean_docs(docs):\n",
    "    cleaned_docs= []\n",
    "\n",
    "    for doc in docs:\n",
    "        metadata= doc.metadata[\"source\"]\n",
    "\n",
    "        cleaned_docs.append(\n",
    "            Document(\n",
    "                page_content= doc.page_content,\n",
    "                metadata= {\"source\": metadata}\n",
    "            )\n",
    "        )\n",
    "    return cleaned_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76e8aead",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_docs= clean_docs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "758531a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data\\\\Medical_book.pdf'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_docs[10].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29ef7f1",
   "metadata": {},
   "source": [
    "2. Text Splitting/Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "127708ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing langchain's text splitter module\n",
    "\"\"\"This module provides functionality to split documents into smaller chunks.\"\"\"\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ed3163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"function to split documents into smaller chunks\"\"\"\n",
    "def split_docs(clean_docs):\n",
    "    text_splitter= RecursiveCharacterTextSplitter(\n",
    "        chunk_size= 500,\n",
    "        chunk_overlap= 20,\n",
    "    )\n",
    "\n",
    "    splitted_docs= text_splitter.split_documents(clean_docs)\n",
    "\n",
    "    print(f\"Number of split documents: {len(splitted_docs)}\")\n",
    "    return splitted_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0d147a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of split documents: 5859\n"
     ]
    }
   ],
   "source": [
    "splitted_docs= split_docs(clean_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9a3d34",
   "metadata": {},
   "source": [
    "3. Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcd33dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import embedding model\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b16642ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\muska\\AppData\\Local\\Temp\\ipykernel_7092\\185403826.py:8: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model= HuggingFaceBgeEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "function to get embedding model.\n",
    "This function initializes and returns a HuggingFaceBgeEmbeddings model using the specified model name.\n",
    "\"\"\"\n",
    "\n",
    "def get_embeddings():\n",
    "    model_name= \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embedding_model= HuggingFaceBgeEmbeddings(\n",
    "        model_name= model_name\n",
    "        )\n",
    "\n",
    "    return embedding_model\n",
    "\n",
    "embedding_model= get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc4e9103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceBgeEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, query_instruction='Represent this question for searching relevant passages: ', embed_instruction='', show_progress=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9f2c062",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector= embedding_model.embed_query(\"Hello world how are you, I am sohel Mulani\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a74d6af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.028469542041420937,\n",
       " 0.11501668393611908,\n",
       " 0.03270135074853897,\n",
       " 0.007951495237648487,\n",
       " -0.0065203639678657055,\n",
       " -0.04722017049789429,\n",
       " 0.06523384153842926,\n",
       " -0.033700983971357346,\n",
       " -0.041105564683675766,\n",
       " -0.04156296327710152,\n",
       " 0.07509908080101013,\n",
       " -0.1089206263422966,\n",
       " -0.009411098435521126,\n",
       " -0.05619879439473152,\n",
       " 0.0847795233130455,\n",
       " -0.009853297844529152,\n",
       " 0.03278208523988724,\n",
       " -0.03715991973876953,\n",
       " -0.11123354732990265,\n",
       " -0.019586894661188126,\n",
       " 0.08424617350101471,\n",
       " 0.08642211556434631,\n",
       " 0.0049339886754751205,\n",
       " 0.0642814189195633,\n",
       " -0.05126078799366951,\n",
       " -0.027468116953969002,\n",
       " 0.019231485202908516,\n",
       " -0.039615798741579056,\n",
       " 0.07078070193529129,\n",
       " -0.01674046739935875,\n",
       " -0.07029733061790466,\n",
       " 0.008218610659241676,\n",
       " 0.09632854163646698,\n",
       " 0.03770509734749794,\n",
       " -0.0495634600520134,\n",
       " 0.14160031080245972,\n",
       " 0.04099220409989357,\n",
       " -0.026685262098908424,\n",
       " -0.01357988454401493,\n",
       " -0.03946810960769653,\n",
       " -0.0065088942646980286,\n",
       " -0.0482693575322628,\n",
       " 0.005567948799580336,\n",
       " -0.05113614350557327,\n",
       " 0.042706601321697235,\n",
       " -0.00987683329731226,\n",
       " -0.039209265261888504,\n",
       " 0.033606886863708496,\n",
       " 0.02621733397245407,\n",
       " -0.003974899183958769,\n",
       " -0.20030978322029114,\n",
       " 1.5547795555903576e-05,\n",
       " -0.03343767300248146,\n",
       " 0.0134818060323596,\n",
       " 0.05660358443856239,\n",
       " -0.03641490265727043,\n",
       " -0.05848279222846031,\n",
       " 0.06414022296667099,\n",
       " 0.013590718619525433,\n",
       " 0.002699629170820117,\n",
       " -0.042037658393383026,\n",
       " 0.006079041864722967,\n",
       " 0.0012632186990231276,\n",
       " 0.037951815873384476,\n",
       " 0.07182970643043518,\n",
       " -0.06057458370923996,\n",
       " -0.006439160089939833,\n",
       " -0.0039081270806491375,\n",
       " -0.060637883841991425,\n",
       " -0.024623315781354904,\n",
       " -0.056520652025938034,\n",
       " -0.04820416122674942,\n",
       " -0.029022250324487686,\n",
       " -0.0033522185403853655,\n",
       " -0.16382619738578796,\n",
       " -0.06607825309038162,\n",
       " -0.00648074084892869,\n",
       " -0.009933162480592728,\n",
       " 0.0462234690785408,\n",
       " 0.09021379798650742,\n",
       " 0.044439587742090225,\n",
       " -0.012397383339703083,\n",
       " 0.05142650753259659,\n",
       " -0.0020531010814011097,\n",
       " -0.016664061695337296,\n",
       " -0.038329850882291794,\n",
       " -0.003305755788460374,\n",
       " -0.03824485465884209,\n",
       " -0.003582039149478078,\n",
       " -0.030739594250917435,\n",
       " 0.016971800476312637,\n",
       " -0.047064557671546936,\n",
       " -0.024228664115071297,\n",
       " -0.0005495253135450184,\n",
       " -0.002429334446787834,\n",
       " -0.0020001463126391172,\n",
       " 0.056000154465436935,\n",
       " 0.012075594626367092,\n",
       " -0.026135750114917755,\n",
       " 0.10479450970888138,\n",
       " 0.01925610564649105,\n",
       " 0.024480784311890602,\n",
       " 0.05963965877890587,\n",
       " 0.02484935335814953,\n",
       " -0.02620566636323929,\n",
       " 0.02122095413506031,\n",
       " -0.058006368577480316,\n",
       " 0.03830701485276222,\n",
       " -0.0025419883895665407,\n",
       " -0.028829650953412056,\n",
       " -0.05907590314745903,\n",
       " -0.08553402870893478,\n",
       " -0.05137769877910614,\n",
       " -0.05485416576266289,\n",
       " 0.097745880484581,\n",
       " -0.008228466846048832,\n",
       " -0.004824942909181118,\n",
       " 0.0681057721376419,\n",
       " -0.051478419452905655,\n",
       " 0.037426065653562546,\n",
       " -0.03998100385069847,\n",
       " 0.07150433212518692,\n",
       " 0.0062414128333330154,\n",
       " 0.09421917796134949,\n",
       " -0.03589161857962608,\n",
       " -0.006895885802805424,\n",
       " 0.0014856174821034074,\n",
       " -1.0143994621978164e-33,\n",
       " 0.11853161454200745,\n",
       " -0.010818597860634327,\n",
       " 0.05876676365733147,\n",
       " 0.09670083224773407,\n",
       " -0.08119557797908783,\n",
       " -0.032052818685770035,\n",
       " -0.004548389930278063,\n",
       " 0.01709987223148346,\n",
       " 0.023951759561896324,\n",
       " -0.048308275640010834,\n",
       " 0.042983051389455795,\n",
       " -0.03250795230269432,\n",
       " 0.0005808158311992884,\n",
       " 0.05739045515656471,\n",
       " -0.0349448136985302,\n",
       " -0.012051819823682308,\n",
       " -0.06470905989408493,\n",
       " -0.050972964614629745,\n",
       " 0.010107968933880329,\n",
       " 0.0613323450088501,\n",
       " -0.003738890402019024,\n",
       " -0.04198574274778366,\n",
       " 0.04181065782904625,\n",
       " -0.03244242072105408,\n",
       " 0.04899671673774719,\n",
       " -0.05894416570663452,\n",
       " 0.054418716579675674,\n",
       " -0.12820953130722046,\n",
       " 0.039510369300842285,\n",
       " 0.05244017392396927,\n",
       " 0.02770083025097847,\n",
       " -0.07635713368654251,\n",
       " -0.06515287607908249,\n",
       " -0.05028858780860901,\n",
       " -0.022116605192422867,\n",
       " 0.01867240108549595,\n",
       " -0.04997637867927551,\n",
       " -0.015639938414096832,\n",
       " -0.07062853872776031,\n",
       " 8.796326255833264e-06,\n",
       " -0.05982706695795059,\n",
       " 0.0032974742352962494,\n",
       " 0.054198041558265686,\n",
       " -0.04049385339021683,\n",
       " -0.051053859293460846,\n",
       " 0.023280426859855652,\n",
       " -0.003144751535728574,\n",
       " 0.05258280783891678,\n",
       " -0.03222236782312393,\n",
       " 0.009133832529187202,\n",
       " -0.06547342240810394,\n",
       " 0.02712487243115902,\n",
       " -0.0989256203174591,\n",
       " 0.03541376814246178,\n",
       " 0.0361202210187912,\n",
       " 0.009979457594454288,\n",
       " -0.004244577139616013,\n",
       " 0.05093086138367653,\n",
       " -0.10299599170684814,\n",
       " 0.06242632120847702,\n",
       " -0.013011611998081207,\n",
       " -0.022326791658997536,\n",
       " 0.018854772672057152,\n",
       " -0.009019678458571434,\n",
       " -0.06219199299812317,\n",
       " -0.06027727574110031,\n",
       " -0.030787425115704536,\n",
       " 0.01563006266951561,\n",
       " 0.10608342289924622,\n",
       " -0.04846865311264992,\n",
       " 0.0025172580499202013,\n",
       " -0.06169919669628143,\n",
       " 0.011278249323368073,\n",
       " 0.09433979541063309,\n",
       " -0.08970000594854355,\n",
       " 0.0002516620443202555,\n",
       " 0.009444043971598148,\n",
       " -0.023141158744692802,\n",
       " 0.019821947440505028,\n",
       " 0.023798372596502304,\n",
       " 0.01502731442451477,\n",
       " 0.09572549909353256,\n",
       " -0.01776636764407158,\n",
       " 0.02853608876466751,\n",
       " -0.008348525501787663,\n",
       " 0.0005496091325767338,\n",
       " 0.07211176306009293,\n",
       " -0.10543086379766464,\n",
       " -0.023528311401605606,\n",
       " 0.0387478768825531,\n",
       " 0.002016984624788165,\n",
       " 0.05686972662806511,\n",
       " 0.046164050698280334,\n",
       " -0.08882863074541092,\n",
       " -0.05351429060101509,\n",
       " -7.860257972525047e-34,\n",
       " 0.12836354970932007,\n",
       " 0.012709944508969784,\n",
       " -0.029660280793905258,\n",
       " -0.023646989837288857,\n",
       " -0.06408187001943588,\n",
       " -0.022071873769164085,\n",
       " 0.05256010964512825,\n",
       " 0.094096340239048,\n",
       " 0.00010120381921296939,\n",
       " 0.062417708337306976,\n",
       " -0.06066550314426422,\n",
       " -0.010170157067477703,\n",
       " 0.08082524687051773,\n",
       " -0.03190196305513382,\n",
       " -0.0037878011353313923,\n",
       " 0.04552645608782768,\n",
       " 0.05835890769958496,\n",
       " 0.06607009470462799,\n",
       " 0.032912954688072205,\n",
       " -0.025078382343053818,\n",
       " -0.029708413407206535,\n",
       " 0.0632837787270546,\n",
       " -0.03371313586831093,\n",
       " -0.029077209532260895,\n",
       " -0.017147673293948174,\n",
       " 0.021729182451963425,\n",
       " 0.010608983226120472,\n",
       " 0.020999323576688766,\n",
       " -0.03303734213113785,\n",
       " 0.016480376943945885,\n",
       " -0.002645936794579029,\n",
       " -0.04205192252993584,\n",
       " -0.11862155050039291,\n",
       " 0.07427754998207092,\n",
       " -0.008872446604073048,\n",
       " -0.0017075513023883104,\n",
       " -0.052785709500312805,\n",
       " -0.0018360164249315858,\n",
       " 0.0012501695891842246,\n",
       " -0.023775627836585045,\n",
       " -0.040435776114463806,\n",
       " 0.07376597076654434,\n",
       " -0.020626192912459373,\n",
       " 0.07088387757539749,\n",
       " -0.003168395021930337,\n",
       " -0.02159295417368412,\n",
       " -0.013342922553420067,\n",
       " 0.030772676691412926,\n",
       " 0.019253158941864967,\n",
       " -0.09370484948158264,\n",
       " -0.002884116256609559,\n",
       " -0.07878638803958893,\n",
       " 0.03421288728713989,\n",
       " -0.07602672278881073,\n",
       " -0.03915707767009735,\n",
       " -0.01560470275580883,\n",
       " -0.023900551721453667,\n",
       " -0.054935768246650696,\n",
       " -0.05567184090614319,\n",
       " -0.03865024819970131,\n",
       " 0.009880265220999718,\n",
       " -0.029698174446821213,\n",
       " -0.006046834867447615,\n",
       " 0.02518433704972267,\n",
       " 0.02662782184779644,\n",
       " -0.01373250037431717,\n",
       " 0.021163389086723328,\n",
       " -0.011044086888432503,\n",
       " -0.014717570506036282,\n",
       " -0.06801405549049377,\n",
       " -0.06282570213079453,\n",
       " -0.14371831715106964,\n",
       " -0.0507013238966465,\n",
       " 0.016551464796066284,\n",
       " -0.0033800348173826933,\n",
       " 0.006686521228402853,\n",
       " -0.036939363926649094,\n",
       " -0.007916810922324657,\n",
       " -0.004113289061933756,\n",
       " -0.01601693592965603,\n",
       " 0.0027658503968268633,\n",
       " -0.0023510309401899576,\n",
       " -0.01678515411913395,\n",
       " -0.016065912321209908,\n",
       " 0.020829223096370697,\n",
       " -0.011738581582903862,\n",
       " 0.05973866581916809,\n",
       " 0.05686226859688759,\n",
       " 0.07088952511548996,\n",
       " 0.048641178756952286,\n",
       " -0.06564481556415558,\n",
       " 0.07773652672767639,\n",
       " -0.042116306722164154,\n",
       " 0.012087974697351456,\n",
       " 0.07437590509653091,\n",
       " -2.6087649374062494e-08,\n",
       " -0.01822870969772339,\n",
       " -0.07265714555978775,\n",
       " -0.006373129319399595,\n",
       " 0.051627449691295624,\n",
       " 0.01727789267897606,\n",
       " 0.11357203871011734,\n",
       " 0.022764094173908234,\n",
       " -0.030110014602541924,\n",
       " -0.08200246095657349,\n",
       " -0.0511162132024765,\n",
       " -0.05486536771059036,\n",
       " 0.08071631193161011,\n",
       " -0.04481874406337738,\n",
       " -0.021250329911708832,\n",
       " 0.06437686085700989,\n",
       " 0.018086476251482964,\n",
       " 0.054264552891254425,\n",
       " 0.009869514033198357,\n",
       " -0.020709477365016937,\n",
       " -0.07219669967889786,\n",
       " 0.09840990602970123,\n",
       " 0.014386747032403946,\n",
       " -0.02734048292040825,\n",
       " 0.03837178647518158,\n",
       " -0.07741661369800568,\n",
       " 0.09663799405097961,\n",
       " 0.04267002269625664,\n",
       " 0.05855856090784073,\n",
       " -0.07771080732345581,\n",
       " 0.051674261689186096,\n",
       " 0.01728758029639721,\n",
       " 0.06263120472431183,\n",
       " -0.0446697361767292,\n",
       " -0.028889024630188942,\n",
       " -0.006196723785251379,\n",
       " -0.007694745436310768,\n",
       " -0.04545650631189346,\n",
       " -0.015302675776183605,\n",
       " 0.039124149829149246,\n",
       " 0.019495179876685143,\n",
       " -0.011353342793881893,\n",
       " 0.07097814977169037,\n",
       " 0.029090844094753265,\n",
       " 0.0308112483471632,\n",
       " 0.08387292176485062,\n",
       " -0.011097750626504421,\n",
       " 0.056028686463832855,\n",
       " 0.015262005850672722,\n",
       " -0.03159794583916664,\n",
       " -0.003612136235460639,\n",
       " -0.023527327924966812,\n",
       " -0.02515309303998947,\n",
       " 0.06152825057506561,\n",
       " 0.07720236480236053,\n",
       " 0.0285886749625206,\n",
       " 0.05241788923740387,\n",
       " -0.0056583513505756855,\n",
       " 0.038940977305173874,\n",
       " 0.001889000297524035,\n",
       " 0.038932252675294876,\n",
       " 0.12707294523715973,\n",
       " 0.055065665394067764,\n",
       " -0.031797077506780624,\n",
       " -0.09086140245199203]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5512320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66450b6a",
   "metadata": {},
   "source": [
    "4. Storing vectors to vectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6848022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PINECONE_API_KEY= os.getenv(\"PINECONE_API_KEY\")\n",
    "OPENAI_API_KEY= os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "240334af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pinecone module\n",
    "\"\"\"\n",
    "This module provides functionality to interact with the Pinecone vector database.\n",
    "Pinecone is a managed vector database service that enables efficient storage and \n",
    "retrieval of high-dimensional vector data. \n",
    "It is commonly used in applications such as machine learning, natural language processing, \n",
    "and recommendation systems to handle large-scale vector embeddings.\n",
    "\n",
    "ServerlessSpec: A class that defines the specifications for creating a serverless Pinecone index.\n",
    "Pinecone: The main class for interacting with the Pinecone service, including creating and managing indexes.\n",
    "\n",
    "\"\"\"\n",
    "from pinecone import Pinecone, ServerlessSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca8276f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pinecone index and initialize pinecone client\n",
    "\n",
    "# define index name\n",
    "index_name= \"medical-assistant\"\n",
    "\n",
    "# initialize pinecone client\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# define serverless specification\n",
    "spec = ServerlessSpec(\n",
    "    cloud=\"aws\", region=\"us-east-1\"\n",
    "    )\n",
    "\n",
    "# create index if it does not exist\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name, \n",
    "        dimension=384, \n",
    "        metric=\"cosine\", \n",
    "        spec=spec\n",
    "        )\n",
    "\n",
    "# connect to the index  \n",
    "index= pc.Index(index_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8954780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import langchain pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "doc_vector_store= PineconeVectorStore.from_documents(\n",
    "    index_name= index_name,\n",
    "    embedding= embedding_model,\n",
    "    documents= splitted_docs\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f1dfc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['89728379-af00-4273-8078-7bafd8fa2aa3']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding more documents to pinecone vector store\n",
    "extra_doc= Document(\n",
    "    page_content= \"This is a sample document to add more documents to pinecone vector store.\",\n",
    "    metadata= {\"source\": \"extra_doc.pdf\"}\n",
    ")\n",
    "doc_vector_store.add_documents([extra_doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664786dd",
   "metadata": {},
   "source": [
    "5. Creating a retriever from the pinecone vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "379b5a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='378ec838-1484-447f-8f5a-343b4284aa87', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='begin to fall. A person with diabetes mellitus either does\\nnot make enough insulin, or makes insulin that does not\\nwork properly. The result is blood sugar that remains\\nhigh, a condition called hyperglycemia.\\nDiabetes must be diagnosed as early as possible. If\\nleft untreated, it can damage or cause failure of the eyes,\\nkidneys, nerves, heart, blood vessels, and other body\\norgans. Hypoglycemia, or low blood sugar, may also be\\ndiscovered through blood sugar testing. Hypoglycemia is'),\n",
       " Document(id='a37486e9-37a6-4bd3-a465-81fd8779db17', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='begin to fall. A person with diabetes mellitus either does\\nnot make enough insulin, or makes insulin that does not\\nwork properly. The result is blood sugar that remains\\nhigh, a condition called hyperglycemia.\\nDiabetes must be diagnosed as early as possible. If\\nleft untreated, it can damage or cause failure of the eyes,\\nkidneys, nerves, heart, blood vessels, and other body\\norgans. Hypoglycemia, or low blood sugar, may also be\\ndiscovered through blood sugar testing. Hypoglycemia is'),\n",
       " Document(id='a3b914dd-88d0-4890-a9d0-93c59dad4f33', metadata={'source': 'data\\\\Medical_book.pdf'}, page_content='Resources\\nBOOKS\\nA Manual of Laboratory and Diagnostic Tests.5th ed. Ed.\\nFrancis Fishback. Philadelphia: Lippincott, 1996.\\nHenry, John B., ed. Clinical Diagnosis and Management by\\nLaboratory Methods. 19th ed. Philadelphia: W. B. Saun-\\nders Co., 1996.\\nPERIODICALS\\nAmerican Diabetes Association. “Report of the Expert Com-\\nmittee on the Diagnosis and Classification of Diabetes\\nMellitus.” Diabetes Care 20, no, 7(July 997): 1183-1197.\\nORGANIZATIONS')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriver= doc_vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\n",
    "retriveed_docs= retriver.invoke(\"What is diabetes?\")\n",
    "retriveed_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f882b94",
   "metadata": {},
   "source": [
    "6. Create LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "360b2ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating OpenAI LLM model for question answering\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm_chatModel= ChatOpenAI(\n",
    "    openai_api_key= OPENAI_API_KEY,\n",
    "    model_name= \"gpt-5-nano\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51356056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import chains module for question answering\n",
    "\n",
    "\"\"\"\n",
    "langchain.chains: This module provides functionality to create and manage chains of operations for various tasks,\n",
    "including retrieval-based question answering.\n",
    "\n",
    "langchain.chains.create_retrieval_chain: A function that creates a retrieval-based question-answering chain.\n",
    "\n",
    "langchain.chains.combine_documents.create_stuff_documents_chain: A function that creates a document combination chain using the \"stuff\" method.\n",
    "\n",
    "langchain_core.prompts.ChatPromptTemplate: A class that defines a chat prompt template for use in chat-based language models.\n",
    "\"\"\"\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9a3f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining system prompt for question answering\n",
    "system_prompt= (\n",
    "    \"You are a helpful medical assistant for question answering tasks. Use the following context to answer the user's question.\"\n",
    "    \"If you don't know the answer, just say that you don't know, don't try to make up an answer.\"\n",
    "    \"Keep your answers short, concise and to the point.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "# create prompt template using system prompt \n",
    "\"\"\"\n",
    "Prompt template for question answering tasks using chat-based language models.\n",
    "ChatPromptTemplate.from_messages: A method that creates a chat prompt template from a list of messages, including system and user messages.\n",
    "Here, the system message contains the system prompt, and the user message is a placeholder for user input.\n",
    "input: The user's question or input that will be used in the prompt template.\n",
    "\"\"\"\n",
    "prompt_template= ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7ebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create retrieval chain for question answering\n",
    "# LLM pipelineb\n",
    "\"\"\"\n",
    "This code creates a retrieval-based question-answering chain using a language model and a prompt template.\n",
    "create_stuff_documents_chain: A function that creates a document combination chain using the \"stuff\" method.\n",
    "llm: The language model to be used for generating answers.\n",
    "prompt: The prompt template to be used for formatting the input and context.\n",
    "create_retrieval_chain: A function that creates a retrieval-based question-answering chain.\n",
    "\"\"\"\n",
    "retrieval_chain= create_stuff_documents_chain(\n",
    "    llm= llm_chatModel,\n",
    "    prompt= prompt_template\n",
    "    )\n",
    "\n",
    "rag_chain= create_retrieval_chain(retriver, retrieval_chain)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55052ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You probably mean acromegaly. It’s a hormonal disorder caused by too much growth hormone, usually from a pituitary tumor, after puberty. This leads to enlargement of hands, feet, and facial features, thickened skin, and joint problems; it can also cause diabetes, high blood pressure, and heart issues. In children, excess GH causes gigantism. Diagnosis involves measuring IGF-1, a GH suppression test, and pituitary MRI. Treatment typically includes removing the tumor (surgery), medications to block GH effects, and sometimes radiation.\n"
     ]
    }
   ],
   "source": [
    "# ask questions to the RAG chain\n",
    "\n",
    "\"\"\"\n",
    "invoke: A method that executes the retrieval-augmented generation (RAG) chain with the provided input.\n",
    "input: The user's question or input to be answered by the RAG chain.\n",
    "\"\"\"\n",
    "query= \"what is acremogaly?\"\n",
    "response= rag_chain.invoke({\"input\": query})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "782c6c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acromegaly is treated mainly to normalize GH/IGF-1 levels and control the pituitary tumor. Options include:\n",
      "\n",
      "- Primary therapy: transsphenoidal surgery to remove the pituitary adenoma (often curative if the tumor is small).\n",
      "\n",
      "- Medical therapy (if surgery isn’t possible or not curative):\n",
      "  - Somatostatin analogs (octreotide, lanreotide) to suppress GH/IGF-1.\n",
      "  - GH receptor antagonist (pegvisomant) to normalize IGF-1.\n",
      "  - Dopamine agonists (cabergoline, bromocriptine) in selected cases with mild disease.\n",
      "\n",
      "- Radiotherapy: for residual or recurrent tumor or when other treatments fail.\n",
      "\n",
      "- Management of comorbidities (diabetes, hypertension, sleep apnea) and regular monitoring of IGF-1 and pituitary function.\n"
     ]
    }
   ],
   "source": [
    "query= \"what is treatment of acremogaly?\"\n",
    "response= rag_chain.invoke({\"input\": query})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
